{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CS4277/CS5477 Assignment 4: Dense 3D model from multi-view stereo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this assignment, you will compute a dense 3D model from multi-view stereo, i.e. the plane sweeping algorithm. \n",
    "\n",
    "**Honour Code.** This coding assignment constitutes 10% of your final grade in CS4277/CS5477. Note that plagiarism will not be condoned! You may discuss with your classmates and check the internet for references, but you MUST NOT submit code/report that is copied directly from other sources!\n",
    "\n",
    "**References:**\n",
    "* Lecture 11\n",
    "\n",
    "**Optional references:**\n",
    "* A space-sweep approach to true multi-image matching \\[[link](https://www.ri.cmu.edu/pub_files/pub1/collins_robert_1996_1/collins_robert_1996_1.pdf)\\]\n",
    "\n",
    "### Instructions\n",
    "This workbook provides the instructions for the assignment, and facilitates the running of your code and visualization of the results. For each part of the assignment, you are required to **complete the implementations of certain functions in the accompanying python file** (`lab4.py`).\n",
    "\n",
    "Please note the following:\n",
    "1. Fill in your name, email, and NUSNET ID at the top of the python file.\n",
    "2. The parts you need to implement are clearly marked with the following:\n",
    "\n",
    "    ```\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "    ```\n",
    "    \n",
    "    , and you should write your code in between the above two lines.\n",
    "3. Note that for each part, there may certain functions that are prohibited to be used. It is important **NOT to use those prohibited functions** (or other functions with similar functionality). If you are unsure whether a particular function is allowed, feel free to ask any of the TAs.\n",
    "\n",
    "\n",
    "### Submission Instructions\n",
    "Items to be submitted:\n",
    "* **Source code (lab4.py).** This is where you fill in all your code.\n",
    "* **Report (report.pdf).** This should describe your implementation and be no more than one page.\n",
    "Please clearly indicate your name and student number (the one that looks like A1234567X) in the report as well as the top of your source code. Zip the two files together and name it in the following format: A1234567X.zip (replace with your student number). Opening the zip file should show:\n",
    "\n",
    "Submit your assignment by **12 April 2024, 2359HRS** to Canvas. 25% of the total score will be deducted for each day of late submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Computation of Plane Sweep Homography\n",
    "As we have discussed in the lectures, two cameras observing a plane are related by a homography. In this part, you will compute the homography that relates two given camera views.\n",
    "\n",
    "Below, we provide the camera intrinsic matrix, as well as the relative pose between the two cameras. To simplify the problem, both cameras share the same intrinsic matrix $K$. The relative pose are given as a $3 \\times 4$ matrix $M_{rel}$ that transforms points in the reference camera frame $(X_r, Y_r, Z_r)$ to the input camera frame $(X_i, Y_i, Z_i)$, i.e.\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X_i \\\\\n",
    "Y_i \\\\\n",
    "Z_i\n",
    "\\end{bmatrix}\n",
    "=\n",
    "M_{rel}\n",
    "\\begin{bmatrix}\n",
    "X_r \\\\\n",
    "Y_r \\\\\n",
    "Z_r \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note that the depths are provided as *inverse* depths $1/d$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport lab4\n",
    "\n",
    "import math\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import k3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lab4 import *\n",
    "\n",
    "np.set_printoptions(precision=6)  # Print less digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T18:33:09.396623Z",
     "start_time": "2024-04-03T18:33:09.392086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Intrinsic matrix\n",
    "K = np.array([[615.,   0., 320.],\n",
    "              [  0., 615., 240.],\n",
    "              [  0.,   0.,   1.]])\n",
    "\n",
    "# relative pose M_rel\n",
    "relative_pose = np.array([[ 0.85666636, -0.07970693,  0.50967593, -5.07139457],\n",
    "                          [ 0.107982  ,  0.99381078, -0.02607722,  2.38452488],\n",
    "                          [-0.5044429 ,  0.07737531,  0.85997118,  1.34159884]])\n",
    "\n",
    "# Inverse depths\n",
    "inv_depths = np.array([0.1, 0.06944444, 0.03888889, 0.00833333])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the following functions(s): get_plane_sweep_homographies()**.\n",
    "\n",
    "Given the above inputs, compute the homographies that relate the images in the two camera for the given (inverse) depths. To simplify the problem, assume that the planes are fronto-parallel with respect to the reference camera. For $D$ inverse depth values, your function should output a matrix of size $(D, 3, 3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T18:33:09.960745Z",
     "start_time": "2024-04-03T18:33:09.397625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3, 1) (1, 3) (3, 3)\n",
      "(4, 3, 3)\n",
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlab4\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_plane_sweep_homographies\n\u001B[1;32m----> 3\u001B[0m homographies \u001B[38;5;241m=\u001B[39m get_plane_sweep_homographies(K, relative_pose, inv_depths)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(homographies)\n",
      "File \u001B[1;32mE:\\Study\\NUS\\CS5477\\cs5477\\Assignment 4\\lab4.py:189\u001B[0m, in \u001B[0;36mget_plane_sweep_homographies\u001B[1;34m(K, relative_pose, inv_depths)\u001B[0m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;66;03m# homographies.append((R.T @ C @ n.T * inv_depths[i]))\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(homographies))\n\u001B[1;32m--> 189\u001B[0m exit(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    191\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\" YOUR CODE ENDS HERE \"\"\"\u001B[39;00m\n\u001B[0;32m    193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(homographies)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "from lab4 import get_plane_sweep_homographies\n",
    "\n",
    "homographies = get_plane_sweep_homographies(K, relative_pose, inv_depths)\n",
    "print(homographies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If implemented correctly, the above should print:\n",
    "```\n",
    "[[[ 5.941920e-01 -3.944661e-02  1.390076e+02]\n",
    "  [-8.887377e-02  1.024006e+00  1.518804e+02]\n",
    "  [-8.202324e-04  1.258135e-04  1.226410e+00]]\n",
    "\n",
    " [[ 5.941920e-01 -3.944661e-02  2.211897e+02]\n",
    "  [-8.887377e-02  1.024006e+00  9.723281e+01]\n",
    "  [-8.202324e-04  1.258135e-04  1.185417e+00]]\n",
    "\n",
    " [[ 5.941920e-01 -3.944661e-02  3.033718e+02]\n",
    "  [-8.887377e-02  1.024006e+00  4.258523e+01]\n",
    "  [-8.202324e-04  1.258135e-04  1.144424e+00]]\n",
    "\n",
    " [[ 5.941920e-01 -3.944661e-02  3.855539e+02]\n",
    "  [-8.887377e-02  1.024006e+00 -1.206237e+01]\n",
    "  [-8.202324e-04  1.258135e-04  1.103430e+00]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Plane Sweep Stereo\n",
    "In this part, you will write the code for performing the plane sweep stereo. We will perform plane sweeps on images from the [Tsukuba](https://home.cvlab.cs.tsukuba.ac.jp/dataset) dataset. \n",
    "\n",
    "The dataset we will work on contains $n=10$ images. We will use one of these as the reference camera view, and warp all images to this view. Let us first load the dataset and visualize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-03T18:33:09.961751Z"
    }
   },
   "outputs": [],
   "source": [
    "from lab4 import load_data\n",
    "\n",
    "ref_id = 4  # use image 4 as the reference view\n",
    "data_folder = 'data/tsukuba'\n",
    "images, K, (img_height, img_width) = load_data(data_folder)\n",
    "ref_pose = images[ref_id].pose_mat\n",
    "print('Reference camera pose:\\n', ref_pose)\n",
    "\n",
    "# Visualizes the source images\n",
    "plt.figure(figsize=(12, 14))\n",
    "num_rows = math.ceil(len(images) / 3)\n",
    "plt.tight_layout()\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(num_rows, 3, i+1)\n",
    "    plt.imshow(images[i].image)\n",
    "    if i == ref_id:\n",
    "        plt.title('Image {} (ref))'.format(i))\n",
    "    else:\n",
    "        plt.title('Image {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are stored as instances of our `Image` class. You can see its implementation in `lab4.py`, but otherwise you should only need to access the following member variables:\n",
    "- `pose_mat`: 3x4 transform $M$ to transform points from world to camera frame, i.e. $p_c = M \\cdot p_w$\n",
    "- `image`: The image bitmap itself\n",
    "\n",
    "Now, the task is to implement the function to compute the plane sweep volume. The steps to do so are as follows:\n",
    "1. Compute the relative pose between each image and the reference view\n",
    "2. For every fronto-parallel plane at depth d,\n",
    "   - Compute the homography transforms to warp each images to this reference view\n",
    "   - Warp the images\n",
    "3. Compute the variance at every pixel and depth. Compute the variance for each of the RGB channels separately, then take the average.\n",
    "\n",
    "Note that not every image will cover every pixel of the reference view at all depths. You need to take this into account when computing the variance (i.e. the variance may be computed on less than $n$ images).\n",
    "\n",
    "After computing the plane sweep volume, the depths can be obtained as the depth that results in the minimum variance.\n",
    "\n",
    "**Implement the following functions(s): compute_plane_sweep_volume(), compute_depths()**\n",
    "\n",
    "Your function should output two variables:\n",
    "1. `ps_volume`: Plane sweep volume of size $(D, H, W)$\n",
    "2. `accum_volume`: Number of valid images considered in computing the variance, with size $(D, H, W)$\n",
    "\n",
    "*Hint: You might find the following functions useful: `get_plane_sweep_homographies()` (from Part 1), and `cv2.warpPerspective()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-03T18:33:09.962752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sweep D=256 planes from 0.8 to 6.0 meters away\n",
    "num_depths = 256\n",
    "inv_depths = np.linspace(1/0.8, 1/8.0, num=num_depths)\n",
    "\n",
    "ps_volume, accum_count = compute_plane_sweep_volume(images, ref_pose, K, inv_depths, \n",
    "                                                    (img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-03T18:33:09.962752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute (inverse) depth from plane sweep volume and visualize\n",
    "inv_depth_img = compute_depths(ps_volume, inv_depths)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(images[ref_id].image)\n",
    "plt.title('Reference image');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(inv_depth_img)\n",
    "plt.title('Estimated depths');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If implemented correctly, the above should show a reasonable estimate of the depths of the reference image (brighter colors indicates nearer objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Unprojection of depth map\n",
    "You will now unproject the depth maps back into colored 3D points. This will allow you to visualize the 3D model as a point cloud.\n",
    "\n",
    "**Implement the following functions(s): unproject_depth_map()**\n",
    "\n",
    "The function should take in the inverse depth maps and output an Nx3 array for the locations and another Nx3 array for RGB values. The function should also take in an optional mask which you will generate in Part 4 to indicate which pixels have confident depth estimates.\n",
    "\n",
    "*You might find the following functions useful: `np.meshgrid()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-03T18:33:09.963751Z"
    }
   },
   "outputs": [],
   "source": [
    "xyz, rgb = unproject_depth_map(images[ref_id].image, inv_depth_img, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see how our model looks like in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-03T18:33:09.963751Z"
    }
   },
   "outputs": [],
   "source": [
    "plot = k3d.plot(grid_visible=False)\n",
    "plt_points = k3d.points(positions=xyz.astype(np.float32), \n",
    "                        colors=rgb2hex(rgb), \n",
    "                        point_size=0.5, shader=\"dot\",)\n",
    "plot += plt_points\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Post Processing\n",
    "You will notice that the above depth map (and subsequently 3D point cloud) is very noisy. In this portion, we try to denoise the depth map and mask out less confident pixels.\n",
    "\n",
    "**Implement the following functions(s): post_process()**\n",
    "\n",
    "No specific instructions are provided for this part, so use your creativity here! Some ideas include:\n",
    "- smoothing filter to denoise the variance estimates, e.g. see `scipy.ndimage.*filter()`.\n",
    "- mask out pixels/depths with large variances.\n",
    "- Consider how many images are used to compute the variance, i.e. the `accum_count` variable\n",
    "\n",
    "A portion of the score for this part will be based on how well the resulting 3D model looks. We will also evaluate on a hold-out image set, so do not cheat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-03T18:33:09.964752Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_depth_img2, valid_mask = post_process(ps_volume, inv_depths, accum_count)\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(inv_depth_img)\n",
    "plt.title('Estimated depths (raw)');\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(inv_depth_img2)\n",
    "plt.title('Estimated depths (denoised)');\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(valid_mask)\n",
    "plt.title('Valid mask');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the denoised unprojected points and see if it looks better now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-03T18:33:09.965752Z"
    }
   },
   "outputs": [],
   "source": [
    "xyz, rgb = unproject_depth_map(images[ref_id].image, inv_depth_img2, K, valid_mask)\n",
    "plot2 = k3d.plot(grid_visible=False)\n",
    "plt_points2 = k3d.points(positions=xyz.astype(np.float32), \n",
    "                        colors=rgb2hex(rgb), \n",
    "                        point_size=0.5, shader=\"dot\",)\n",
    "plot2 += plt_points2\n",
    "plot2.display()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "cs5477",
   "language": "python",
   "display_name": "cs5477"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
